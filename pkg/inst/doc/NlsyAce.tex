% \VignetteIndexEntry{ACE Models with the NLSY}
% \VignetteEngine{knitr::knitr} 
\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{color}
\usepackage[margin=1.0in]{geometry}
\usepackage[colorlinks=true,urlcolor=darkblue,linkcolor=greenteal]{hyperref}  %This makes reference links hyperlinks in pdf (tip from Revelle's 'psych' package).
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent (tip from Revelle's 'psych' package).
% \usepackage[pdftex]{graphicx}
\usepackage{amssymb,amsmath} %ftp://ftp.ams.org/ams/doc/amsmath/short-math-guide.pdf
\definecolor{darkblue}{rgb}{.0,0.2,.8}
\definecolor{greenteal}{rgb}{0,0.5,.5}

\title{ACE Models with the NLSY}
\author{
  \href{http://scholar.google.com/citations?user=ffsJTC0AAAAJ}{William Howard Beasley} (\href{http://howardliveoak.com/}{Howard Live Oak LLC}, Norman)\\
  \href{http://www.vanderbilt.edu/psychological_sciences/bio/joe-rodgers}{Joseph Lee Rodgers} (Vanderbilt University, Nashville)\\
  \href{http://find.ouhsc.edu/Faculty.aspx?FacultyID=1041}{David Bard} (University of Oklahoma Health Sciences Center, OKC)\\
  Kelly Meredith (Oklahoma City University, OKC)\\
  \href{http://students.ou.edu/H/Michael.D.Hunter-1/}{Michael D. Hunter} (University of Oklahoma, Norman)
}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\pkg}[1]{\textsf{\small{#1}}}
\newcommand{\R}{\textsf{R}} %(tip from Revelle's 'psych' package).

\maketitle
%\href{http://personality-project.org/r/r.guide.html}{dss}

\begin{abstract}
   We describe how to use the \pkg{NlsyLinks} package to examine various biometric models, using the NLSY79.
\end{abstract}
\tableofcontents



%\href{http://personality-project.org/r/r.guide.html}{dss}

%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Terminology} %\label{sec:Terminology}
This package considers both Gen1 and Gen2 subjects.  \textbf{Gen1} refers to subjects in the original NLSY79 sample (\url{http://www.bls.gov/nls/nlsy79.htm}).  \textbf{Gen2} subjects are the biological offspring of the Gen1 females -\emph{i.e.}, those in the NLSY79 Children and Young Adults sample ( \url{http://www.bls.gov/nls/nlsy79ch.htm}).  The NLSY97 is a third dataset that can be used for behavior genetic research (\url{http://www.bls.gov/nls/nlsy97.htm}), although this vignette focuses on the two generations in the NLSY79.

Standard terminology is to refer Gen2 subjects as `children' when they are younger than age 15 (NSLY79-C), and as `young adults' when they are 15 and older (NLSY79-YA); though they are the same respondents, different funding mechanisms and different survey items necessitate the distinction.  This cohort is sometimes abbreviated as `NLSY79-C', `NLSY79C', `NLSY-C' or `NLSYC'. 

The \textbf{SubjectTag}\phantomsection\label{term:SubjectTag} variable uniquely identify NLSY79 subjects when a dataset contains both generations.  For Gen2 subjects, the \code{SubjectTag} is identical to their CID (\emph{i.e.}, C00001.00 -the ID assigned in the NLSY79-Children files).  However for Gen1 subjects, the \code{SubjectTag} is their CaseID (\emph{i.e.}, R00001.00), with ``00" appended.  This manipulation is necessary to identify subjects uniquely in inter-generational datasets.  A Gen1 subject with an ID of 43 becomes 4300.  The \code{SubjectTag}s of her four children remain 4301, 4302, 4303, and 4304.

The \textbf{expected coefficient of relatedness} of a pair of subjects is typically represented by the variable \code{R}.  Examples are: Monozygotic twins have \code{R}=1; dizygotic twins have \code{R}=0.5; full siblings (\emph{i.e.}, those who share both biological parents) have \code{R}=0.5;  half-siblings (\emph{i.e.}, those who share exactly one biological parent) have \code{R}=0.25; adopted siblings have \code{R}=0.0.  Other possibilities exist too.  The font (and hopefully their context) should distinguish the variable \code{R} from the software \R{}.

A subject's \code{\textbf{ExtendedID}} indicates their extended family.  Two subjects will be in the same extended family if either: [1] they are Gen1 housemates, [2] they are Gen2 siblings, [3] they are Gen2 cousins (\emph{i.e.}, they have mothers who are Gen1 sisters in the NLSY79), [4] they are mother and child (in Gen1 and Gen2, respectively), or [5] they are (aunt|uncle) and (niece|nephew) (in Gen1 and Gen2, respectively).

An \textbf{outcome variable} is directly relevant to the applied researcher; these might represent constructs like height, IQ, and income.  A \textbf{plumbing variable} is necessary to manage BG datasets; examples are \code{R}, a subject's ID, and the date of a subject's last survey.

An ACE model is the basic biometrical model used by Behavior Genetic researchers, where the genetic and environmental effects are assumed to be additive. The three primary variance components are (1) the proportion of variability due to a shared genetic influence (typically represented as $a^2$, or sometimes $h^2$), (2) the proportion of variability due to shared common environmental influence (typically $c^2$), and (3) the proportion of variability due to unexplained/residual/error influence (typically $e^2$).  

The variables are scaled so that they account for all observed variability in the outcome variable; specifically: $a^2 + c^2 + e^2 = 1$.  Using appropriate designs that can logically distinguish these different components (under carefully specified assumptions), the basic biometrical modeling strategy is to estimate the magnitude of $a^2$, $c^2$, and $e^2$ within the context of a particular model. For gentle introductions to Behavior Genetic research, we recommend Plomin (1990) and Carey (2003).  For more in-depth ACE model-fitting strategies, we recommend Neale \& Cardon (1992). 
//This paragraph may get moved to the yet-to-be-written introduction that precedes the Terminology section.

The \textbf{NLS Investigator}\phantomsection\label{term:NlsInvestigator} (\url{http://www.nlsinfo.org/investigator/}) is the best way to obtain the NLSY79 and NLSY97 datasets.  See our vignette dedicated to the NLS Investigator by typing\\ \code{vignette("NlsInvestigator")} or by visiting \url{http://cran.r-project.org/web/packages/NlsyLinks/}.

Before starting the real examples, first verify that the \pkg{NlsyLinks} package is installed correctly.  If not, refer to \hyperref[sec:InstallingPackage]{Appendix \ref*{sec:InstallingPackage}}.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{any}\hlstd{(}\hlkwd{.packages}\hlstd{(}\hlkwc{all.available} \hlstd{=} \hlnum{TRUE}\hlstd{)} \hlopt{==} \hlstr{"NlsyLinks"}\hlstd{)}  \hlcom{#Should evaluate to TRUE.}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlkwd{require}\hlstd{(NlsyLinks)}  \hlcom{#Load the package into the current session.}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Loading required package: NlsyLinks}}\end{kframe}
\end{knitrout}

The package's documentation manual can be opened by typing \code{?NlsyLinks} in
\R{} or RStudio.


%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example: DF analysis with a Simple Outcome for Gen2 Subjects, Using a Package Variable}
The vignette's first example uses a simple statistical model and all available Gen2 subjects.  The \\\code{CreatePairLinksDoubleEntered} function will create a data frame where each represents one pair of siblings, respective of order (\emph{i.e.}, there is a row for Subjects 201 and 202, and a second row for Subjects 202 and 201). This function examines the subjects' IDs and determines who is related to whom (and by how much).  By default, each row it produces has at least six values/columns: (i) ID for the older member of the kinship pair: \code{Subject1Tag}, (ii) ID for the younger member: \code{Subject2Tag}, (iii) ID for their extended family: \code{ExtendedID}, (iv) their estimated coefficient of genetic relatedness: \code{R}, (v \emph{and beyond}) outcome values for the older member; (vi \emph{and beyond}) outcome values for the younger member.  

A DeFries-Fulker (\textbf{DF}) Analysis uses linear regression to estimate the $a^2$, $c^2$, and $e^2$ of a univariate biometric system.  The interpretations of the DF analysis can be found in Rodgers \& Kohler (2005) and Rodgers, Rowe, \& Li (1999).  This  vignette example uses the newest variation, which estimates two parameters; the corresponding function is called \code{DeFriesFulkerMethod3}.
The steps are:
\begin{enumerate}
\item Use the \hyperref[term:NlsInvestigator]{NLS Investigator} to select and download a Gen2 dataset.  

\item Open \R{} and create a new script (see \hyperref[sec:RScripts]{Appendix \ref*{sec:RScripts}}) and load the \pkg{NlsyLinks} package.  If you haven't done so, first install the \pkg{NlsyLinks} package (see \hyperref[sec:InstallingPackage]{Appendix \ref*{sec:InstallingPackage}}).
%\item Within the \R{} script, identify the locations of the downloaded data file, and load it into a data frame.  
\item Within the \R{} script, load the linking dataset.  Then select only Gen2 subjects.  The `Pair' version of the linking dataset is essentially an upper triangle of a symmetric sparse matrix.
\item Load and assign the \code{ExtraOutcomes79} dataset.
\item Specify the outcome variable name and filter out all subjects who have a negative value in this variable.  The NLSY typically uses negative values to indicate different types of missingness (see `Further Information' below).   
\item Create a double-entered file by calling the \code{CreatePairLinksDoubleEntered} function.  At minimum, pass the (i) outcome dataset, the (ii) linking dataset, and the (iii) name(s) of the outcome variable(s).  \emph{(There are occasions when a single-entered file is more appropriate for a DF analysis.  See Rodgers \& Kohler, 2005, for additional information.)}
\item Use \code{DeFriesFulkerMethod3} function (i.e., general linear model) to estimate the coefficients of the DF model.  
\end{enumerate}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### R Code for Example DF analysis with a simple outcome and Gen2 subjects}
\hlcom{#Step 2: Load the package containing the linking routines.}
\hlkwd{require}\hlstd{(NlsyLinks)}

\hlcom{#Step 3: Load the LINKING dataset and filter for the Gen2 subjects}
\hlstd{dsLinking} \hlkwb{<-} \hlkwd{subset}\hlstd{(Links79Pair, RelationshipPath}\hlopt{==}\hlstr{"Gen2Siblings"}\hlstd{)}
\hlkwd{summary}\hlstd{(dsLinking)} \hlcom{#Notice there are 11,088 records (one for each unique pair).}
\end{alltt}
\begin{verbatim}
##    ExtendedID    SubjectTag_S1     SubjectTag_S2           R        
##  Min.   :    2   Min.   :    201   Min.   :    202   Min.   :0.250  
##  1st Qu.: 3155   1st Qu.: 315501   1st Qu.: 315503   1st Qu.:0.250  
##  Median : 6114   Median : 611402   Median : 611404   Median :0.500  
##  Mean   : 5933   Mean   : 593658   Mean   : 593660   Mean   :0.417  
##  3rd Qu.: 8511   3rd Qu.: 851101   3rd Qu.: 851103   3rd Qu.:0.500  
##  Max.   :12673   Max.   :1267301   Max.   :1267302   Max.   :1.000  
##        RelationshipPath
##  Gen1Housemates:    0  
##  Gen2Siblings  :11088  
##  Gen2Cousins   :    0  
##  ParentChild   :    0  
##  AuntNiece     :    0  
## 
\end{verbatim}
\begin{alltt}
\hlcom{#Step 4: Load the OUTCOMES dataset, and then examine the summary.}
\hlstd{dsOutcomes} \hlkwb{<-} \hlstd{ExtraOutcomes79} \hlcom{#'ds' stands for 'Data Set'}
\hlkwd{summary}\hlstd{(dsOutcomes)}
\end{alltt}
\begin{verbatim}
##    SubjectTag        SubjectID         Generation   AfqtRescaled2006Gaussified
##  Min.   :    100   Min.   :      1   Min.   :1.00   Min.   :-3                
##  1st Qu.: 314025   1st Qu.:   5998   1st Qu.:1.00   1st Qu.:-1                
##  Median : 620050   Median :  12000   Median :1.00   Median : 0                
##  Mean   : 618600   Mean   : 289254   Mean   :1.48   Mean   : 0                
##  3rd Qu.: 914501   3rd Qu.: 577403   3rd Qu.:2.00   3rd Qu.: 0                
##  Max.   :1268600   Max.   :1267501   Max.   :2.00   Max.   : 3                
##                                                     NA's   :12276             
##  HeightZGender  HeightZGenderAge WeightZGender   WeightZGenderAge      Afi       
##  Min.   :-3     Min.   :-3       Min.   :-3      Min.   :-4       Min.   : 2     
##  1st Qu.:-1     1st Qu.:-1       1st Qu.:-1      1st Qu.:-1       1st Qu.:15     
##  Median : 0     Median : 0       Median : 0      Median : 0       Median :17     
##  Mean   : 0     Mean   : 0       Mean   : 0      Mean   : 0       Mean   :17     
##  3rd Qu.: 1     3rd Qu.: 1       3rd Qu.: 0      3rd Qu.: 0       3rd Qu.:18     
##  Max.   : 3     Max.   : 3       Max.   : 8      Max.   : 7       Max.   :27     
##  NA's   :5029   NA's   :5030     NA's   :12104   NA's   :12105    NA's   :12740  
##       Afm        MathStandardized
##  Min.   : 0      Min.   : 65     
##  1st Qu.:12      1st Qu.: 91     
##  Median :13      Median :100     
##  Mean   :13      Mean   :100     
##  3rd Qu.:14      3rd Qu.:110     
##  Max.   :19      Max.   :135     
##  NA's   :18165   NA's   :15048
\end{verbatim}
\begin{alltt}
\hlcom{#Step 5: This step isn't necessary for this example, because Kelly Meredith already }
\hlcom{#   groomed the values.  If the negative values (which represent NLSY missing or }
\hlcom{#   skip patterns) still exist, then:}
\hlstd{dsOutcomes}\hlopt{$}\hlstd{MathStandardized[dsOutcomes}\hlopt{$}\hlstd{MathStandardized} \hlopt{<} \hlnum{0}\hlstd{]} \hlkwb{<-} \hlnum{NA}

\hlcom{#Step 6: Create the double entered dataset.}
\hlstd{dsDouble} \hlkwb{<-} \hlkwd{CreatePairLinksDoubleEntered}\hlstd{(}
  \hlkwc{outcomeDataset}\hlstd{=dsOutcomes,}
  \hlkwc{linksPairDataset}\hlstd{=dsLinking,}
  \hlkwc{outcomeNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'MathStandardized'}\hlstd{)}
\hlstd{)}
\hlkwd{summary}\hlstd{(dsDouble)} \hlcom{#Notice there are 22176=(2*11088) records now (two for each unique pair).}
\end{alltt}
\begin{verbatim}
##  SubjectTag_S1     SubjectTag_S2       ExtendedID          R        
##  Min.   :    201   Min.   :    201   Min.   :    2   Min.   :0.250  
##  1st Qu.: 315502   1st Qu.: 315502   1st Qu.: 3155   1st Qu.:0.250  
##  Median : 611404   Median : 611404   Median : 6114   Median :0.500  
##  Mean   : 593659   Mean   : 593659   Mean   : 5933   Mean   :0.417  
##  3rd Qu.: 851102   3rd Qu.: 851102   3rd Qu.: 8511   3rd Qu.:0.500  
##  Max.   :1267302   Max.   :1267302   Max.   :12673   Max.   :1.000  
##                                                                     
##        RelationshipPath MathStandardized_S1 MathStandardized_S2
##  Gen1Housemates:    0   Min.   : 65         Min.   : 65        
##  Gen2Siblings  :22176   1st Qu.: 89         1st Qu.: 89        
##  Gen2Cousins   :    0   Median : 98         Median : 98        
##  ParentChild   :    0   Mean   : 98         Mean   : 98        
##  AuntNiece     :    0   3rd Qu.:108         3rd Qu.:108        
##                         Max.   :135         Max.   :135        
##                         NA's   :3815        NA's   :3815
\end{verbatim}
\begin{alltt}
\hlcom{#Step 7: Estimate the ACE components with a DF Analysis }
\hlstd{ace} \hlkwb{<-} \hlkwd{DeFriesFulkerMethod3}\hlstd{(}
    \hlkwc{dataSet}\hlstd{=dsDouble,}
    \hlkwc{oName_S1}\hlstd{=}\hlstr{"MathStandardized_S1"}\hlstd{,}
    \hlkwc{oName_S2}\hlstd{=}\hlstr{"MathStandardized_S2"}\hlstd{)}
\hlstd{ace}
\end{alltt}
\begin{verbatim}
## [1] "Results of ACE estimation: [show]"
##  ASquared  CSquared  ESquared CaseCount 
## 8.480e-01 4.477e-02 1.073e-01 1.678e+04
\end{verbatim}
\end{kframe}
\end{knitrout}


\emph{Further Information}: If the different reasons of missingness are important, further work is necessary.  For instance, some analyses that use item \code{Y19940000} might need to distinguish a response of ``Don't Know" (which is coded as -2) from ``Missing" (which is coded as -7).  For this vignette example, we'll assume it's safe to clump the responses together.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example: DF analysis with a univariate outcome from a Gen2 Extract}
The vignette's second example differs from the previous example in two ways.  First, the outcome variables are read from a CSV (\href{http://en.wikipedia.org/wiki/Comma-separated_values}{comma separated values} file) that was downloaded from the \hyperref[term:NlsInvestigator]{NLS Investigator}.  Second, the DF analysis is called through the function \code{AceUnivariate}; this function is a wrapper around some simple ACE methods, and will help us smoothly transition to more techniques later in the vignette.   

The steps are:
\begin{enumerate}
\item Use the \hyperref[term:NlsInvestigator]{NLS Investigator} to select and download a Gen2 dataset.  Select the variables `length of gestation of child in weeks' (\code{C03280.00}), `weight of child at birth in ounces' (\code{C03286.00}), and `length of child at birth' (\code{C03288.00}), and then download the *.zip file to your local computer.

\item Open \R{} and create a new script (see \hyperref[sec:RScripts]{Appendix \ref*{sec:RScripts}}) and load the \pkg{NlsyLinks} package.
\item Within the \R{} script, load the linking dataset.  Then select only Gen2 subjects.
\item Read the CSV into \R{} as a \code{data.frame} using \code{ReadCsvNlsy79Gen2}.
\item Verify the desired outcome column exists, and rename it something meaningful to your project.  It is important that the \code{data.frame} is reassigned (\emph{i.e.}, \code{ds <- RenameNlsyColumn(...)}).  In this example, we rename column \code{C0328800} to \code{BirthWeightInOunces}.
\item Filter out all subjects who have a negative \code{BirthWeightInOunces} value.  See the `Further Information' note in the previous example.
\item Create a double-entered file by calling the \code{CreatePairLinksDoubleEntered} function.  At minimum, pass the (i) outcome dataset, the (ii) linking dataset, and the (iii) name(s) of the outcome variable(s). 
\item Call the \code{AceUnivariate} function to estimate the coefficients.
\end{enumerate}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### R Code for Example of a DF analysis with a simple outcome and Gen2 subjects}
\hlcom{#Step 2: Load the package containing the linking routines.}
\hlkwd{require}\hlstd{(NlsyLinks)}

\hlcom{#Step 3: Load the linking dataset and filter for the Gen2 subjects}
\hlstd{dsLinking} \hlkwb{<-} \hlkwd{subset}\hlstd{(Links79Pair, RelationshipPath}\hlopt{==}\hlstr{"Gen2Siblings"}\hlstd{)}

\hlcom{#Step 4: Load the outcomes dataset from the hard drive and then examine the summary.}
\hlcom{#   Your path might be: filePathOutcomes <- 'C:/BGResearch/NlsExtracts/Gen2Birth.csv'}
\hlstd{filePathOutcomes} \hlkwb{<-} \hlkwd{file.path}\hlstd{(}\hlkwd{path.package}\hlstd{(}\hlstr{"NlsyLinks"}\hlstd{),} \hlstr{"extdata"}\hlstd{,} \hlstr{"Gen2Birth.csv"}\hlstd{)}
\hlstd{dsOutcomes} \hlkwb{<-} \hlkwd{ReadCsvNlsy79Gen2}\hlstd{(filePathOutcomes)}
\hlkwd{summary}\hlstd{(dsOutcomes)}
\end{alltt}
\begin{verbatim}
##    SubjectTag        SubjectID         ExtendedID      Generation SubjectTagOfMother
##  Min.   :    201   Min.   :    201   Min.   :    2   Min.   :2    Min.   :    200   
##  1st Qu.: 310302   1st Qu.: 310302   1st Qu.: 3101   1st Qu.:2    1st Qu.: 310300   
##  Median : 604607   Median : 604607   Median : 6045   Median :2    Median : 604600   
##  Mean   : 601313   Mean   : 601313   Mean   : 6007   Mean   :2    Mean   : 601311   
##  3rd Qu.: 876202   3rd Qu.: 876202   3rd Qu.: 8757   3rd Qu.:2    3rd Qu.: 876200   
##  Max.   :1267501   Max.   :1267501   Max.   :12675   Max.   :2    Max.   :1267500   
##                                      NA's   :2                                      
##     C0005300       C0005400        C0005700       C0328000       C0328600  
##  Min.   :1.00   Min.   :-3.00   Min.   :  -3   Min.   :-7.0   Min.   : -7  
##  1st Qu.:2.00   1st Qu.: 1.00   1st Qu.:1981   1st Qu.:37.0   1st Qu.: 99  
##  Median :3.00   Median : 1.00   Median :1985   Median :39.0   Median :115  
##  Mean   :2.34   Mean   : 1.49   Mean   :1986   Mean   :33.5   Mean   :104  
##  3rd Qu.:3.00   3rd Qu.: 2.00   3rd Qu.:1990   3rd Qu.:39.0   3rd Qu.:128  
##  Max.   :3.00   Max.   : 2.00   Max.   :2008   Max.   :51.0   Max.   :768  
##                                                                            
##     C0328800   
##  Min.   :-7.0  
##  1st Qu.:18.0  
##  Median :20.0  
##  Mean   :16.5  
##  3rd Qu.:21.0  
##  Max.   :48.0  
## 
\end{verbatim}
\begin{alltt}
\hlcom{#Step 5: Verify and rename an existing column.}
\hlkwd{VerifyColumnExists}\hlstd{(dsOutcomes,} \hlstr{"C0328600"}\hlstd{)} \hlcom{#Should return '10' in this example.}
\end{alltt}
\begin{verbatim}
## [1] 10
\end{verbatim}
\begin{alltt}
\hlstd{dsOutcomes} \hlkwb{<-} \hlkwd{RenameNlsyColumn}\hlstd{(dsOutcomes,} \hlstr{"C0328600"}\hlstd{,} \hlstr{"BirthWeightInOunces"}\hlstd{)}

\hlcom{#Step 6: For this item, a negative value indicates the parent refused, didn't know, }
\hlcom{#   invalidly skipped, or was missing for some other reason.  }
\hlcom{#   For our present purposes, we'll treat these responses equivalently.}
\hlcom{#   Then clip/Winsorized/truncate the weight to something reasonable.}
\hlstd{dsOutcomes}\hlopt{$}\hlstd{BirthWeightInOunces[dsOutcomes}\hlopt{$}\hlstd{BirthWeightInOunces} \hlopt{<} \hlnum{0}\hlstd{]} \hlkwb{<-} \hlnum{NA}
\hlstd{dsOutcomes}\hlopt{$}\hlstd{BirthWeightInOunces} \hlkwb{<-} \hlkwd{pmin}\hlstd{(dsOutcomes}\hlopt{$}\hlstd{BirthWeightInOunces,} \hlnum{200}\hlstd{)}

\hlcom{#Step 7: Create the double entered dataset.}
\hlstd{dsDouble} \hlkwb{<-} \hlkwd{CreatePairLinksDoubleEntered}\hlstd{(}
  \hlkwc{outcomeDataset}\hlstd{=dsOutcomes,}
  \hlkwc{linksPairDataset}\hlstd{=dsLinking,}
  \hlkwc{outcomeNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'BirthWeightInOunces'}\hlstd{)}
\hlstd{)}

\hlcom{#Step 8: Estimate the ACE components with a DF Analysis }
\hlstd{ace} \hlkwb{<-} \hlkwd{AceUnivariate}\hlstd{(}
  \hlkwc{method}\hlstd{=}\hlstr{"DeFriesFulkerMethod3"}\hlstd{,}
  \hlkwc{dataSet}\hlstd{=dsDouble,}
  \hlkwc{oName_S1}\hlstd{=}\hlstr{"BirthWeightInOunces_S1"}\hlstd{,}
  \hlkwc{oName_S2}\hlstd{=}\hlstr{"BirthWeightInOunces_S2"}
\hlstd{)}
\hlstd{ace}
\end{alltt}
\begin{verbatim}
## [1] "Results of ACE estimation: [show]"
##  ASquared  CSquared  ESquared CaseCount 
## 5.042e-01 1.777e-01 3.182e-01 1.744e+04
\end{verbatim}
\end{kframe}
\end{knitrout}


For another example of incorporating CSVs downloaded from the NLS Investigator, please see the ``Race and Gender Variables'' entry in the \href{http://cran.r-project.org/web/packages/NlsyLinks/vignettes/Faq.pdf}{FAQ}.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example: Multiple Group SEM of a Simple Outcome for Gen2 Subjects}
The example differs from the first one by the statistical mechanism used to estimate the components.  The first example uses multiple regression to estimate the influence of the shared genetic and environmental factors, while this example uses structural equation modeling (SEM).

The \code{CreatePairLinksSingleEntered} function will create a \code{data.frame} where each row represents one unique pair of siblings, \emph{irrespective of order}.  Other than producing half the number of rows, this function is identical to \code{CreatePairLinksDoubleEntered}.

The steps are:

(Steps 1-5 proceed identically to the first example.)
\begin{enumerate}
\setcounter{enumi}{5}   
%6
\item Create a \emph{single}-entered file by calling the \code{CreatePairLinksSingleEntered} function.  At minimum, pass the (i) outcome dataset, the (ii) linking dataset, and the (iii) name(s) of the outcome variable(s). 
%7
\item Declare the names of the outcome variables corresponding to the two members in each pair.  Assuming the variable is called `ZZZ' and the preceeding steps have been followed, the variable `ZZZ\_S1' corresponds to the first members and ZZZ\_S2' corresponds to the second members. 
%8
\item Create a GroupSummary \code{data.frame}, which identifies the \code{R} groups that should be considered by the model.  Inspect the output to see if the groups show unexpected or fishy differences.
%9
\item Create a \code{data.frame} with cleaned variables to pass to the SEM function.  This \code{data.frame} contains only the three necessary rows and columns.
%10
\item Estimate the SEM with the \pkg{lavaan} package.  The function returns an \code{S4} object, which shows the basic ACE information.
%11
\item Inspect details of the SEM, beyond the ACE components.  In this example, we look at the fit stats and the parameter estimates.  The \pkg{lavaan} package has additional methods that may be useful for your purposes.
\end{enumerate}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### R Code for Example lavaan estimation analysis with a simple outcome and Gen2 subjects}
\hlcom{#Steps 1-5 are explained in the vignette's first example:}
\hlkwd{require}\hlstd{(NlsyLinks)}
\hlstd{dsLinking} \hlkwb{<-} \hlkwd{subset}\hlstd{(Links79Pair, RelationshipPath}\hlopt{==}\hlstr{"Gen2Siblings"}\hlstd{)}
\hlstd{dsOutcomes} \hlkwb{<-} \hlstd{ExtraOutcomes79}
\hlstd{dsOutcomes}\hlopt{$}\hlstd{MathStandardized[dsOutcomes}\hlopt{$}\hlstd{MathStandardized} \hlopt{<} \hlnum{0}\hlstd{]} \hlkwb{<-} \hlnum{NA}

\hlcom{#Step 6: Create the single entered dataset.}
\hlstd{dsSingle} \hlkwb{<-} \hlkwd{CreatePairLinksSingleEntered}\hlstd{(}\hlkwc{outcomeDataset}\hlstd{=dsOutcomes,}
  \hlkwc{linksPairDataset}\hlstd{=dsLinking,} \hlkwc{outcomeNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'MathStandardized'}\hlstd{))}

\hlcom{#Step 7: Declare the names for the two outcome variables. }
\hlstd{oName_S1} \hlkwb{<-} \hlstr{"MathStandardized_S1"} \hlcom{#Stands for Outcome1}
\hlstd{oName_S2} \hlkwb{<-} \hlstr{"MathStandardized_S2"} \hlcom{#Stands for Outcome2}

\hlcom{#Step 8: Summarize the R groups and determine which groups can be estimated.}
\hlstd{dsGroupSummary} \hlkwb{<-} \hlkwd{RGroupSummary}\hlstd{(dsSingle, oName_S1, oName_S2)}
\hlstd{dsGroupSummary}
\end{alltt}
\begin{verbatim}
##       R Included PairCount O1Mean O2Mean O1Variance O2Variance O1O2Covariance
## 1 0.250     TRUE      2718  94.64  95.60      169.7      207.8          41.08
## 2 0.375     TRUE       139  92.60  93.17      172.5      187.1          40.48
## 3 0.500     TRUE      5511  99.89 100.18      230.5      233.0         107.37
## 4 0.750    FALSE         2 108.50 106.00      220.5       18.0          63.00
## 5 1.000     TRUE        22  98.64  95.55      319.2      343.1         277.59
##   Correlation Determinant PosDefinite
## 1      0.2188       33573        TRUE
## 2      0.2253       30639        TRUE
## 3      0.4633       42172        TRUE
## 4      1.0000           0       FALSE
## 5      0.8388       32466        TRUE
\end{verbatim}
\begin{alltt}
\hlcom{#Step 9: Create a cleaned dataset}
\hlstd{dsClean} \hlkwb{<-} \hlkwd{CleanSemAceDataset}\hlstd{(}\hlkwc{dsDirty}\hlstd{=dsSingle, dsGroupSummary, oName_S1, oName_S2)}

\hlcom{#Step 10: Run the model}
\hlstd{ace} \hlkwb{<-} \hlkwd{AceLavaanGroup}\hlstd{(dsClean)}
\hlstd{ace}
\end{alltt}
\begin{verbatim}
## [1] "Results of ACE estimation: [show]"
##  ASquared  CSquared  ESquared CaseCount 
##    0.6673    0.1188    0.2139 8390.0000
\end{verbatim}
\begin{alltt}
\hlcom{#Notice the `CaseCount' is 8,390 instead of 17,440.}
\hlcom{#  This is because (a) one pair with R=.75 was excluded, and}
\hlcom{#  (b) the SEM uses a single-entered dataset instead of double-entered.}
\hlcom{#}
\hlcom{#Step 11: Inspect the output further}
\hlkwd{require}\hlstd{(lavaan)} \hlcom{#Load the package to access methods of the lavaan class.}
\hlkwd{GetDetails}\hlstd{(ace)}
\end{alltt}
\begin{verbatim}
## lavaan (0.5-14) converged normally after  62 iterations
## 
##   Number of observations per group         
##   1                                               2718
##   2                                                139
##   3                                               5511
##   4                                                 22
## 
##   Estimator                                         ML
##   Minimum Function Test Statistic              447.272
##   Degrees of freedom                                16
##   P-value (Chi-square)                           0.000
## 
## Chi-square for each group:
## 
##   1                                            282.194
##   2                                             32.858
##   3                                            127.880
##   4                                              4.339
\end{verbatim}
\begin{alltt}
\hlcom{#Examine fit stats like Chi-Squared, RMSEA, CFI, etc.}
\hlkwd{fitMeasures}\hlstd{(}\hlkwd{GetDetails}\hlstd{(ace))} \hlcom{#'fitMeasures' is defined in the lavaan package.}
\end{alltt}
\begin{verbatim}
##              fmin             chisq                df            pvalue 
##             0.027           447.272            16.000             0.000 
##    baseline.chisq       baseline.df   baseline.pvalue               cfi 
##          1499.091             4.000             0.000             0.712 
##               tli              nnfi               rfi               nfi 
##             0.928             0.928             0.925             0.702 
##              pnfi               ifi               rni              logl 
##             2.807             0.709             0.712        -68369.132 
## unrestricted.logl              npar               aic               bic 
##        -68145.496             4.000        136746.264        136774.404 
##            ntotal              bic2             rmsea    rmsea.ci.lower 
##          8390.000        136761.692             0.113             0.104 
##    rmsea.ci.upper      rmsea.pvalue               rmr        rmr_nomean 
##             0.123             0.000            13.895            17.820 
##              srmr       srmr_nomean             cn_05             cn_01 
##             0.128             0.093           494.269           601.260 
##               gfi              agfi              pgfi               mfi 
##             0.999             0.999             0.799             0.975
\end{verbatim}
\begin{alltt}
\hlcom{#Examine low-level details like each group's individual parameter estimates and standard}
\hlcom{#  errors.  Uncomment the next line to view the entire output (which is roughly 4 pages).}
\hlcom{#summary(GetDetails(ace))}
\end{alltt}
\end{kframe}
\end{knitrout}


%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example: Multiple Group SEM of a Simple Outcome for Gen1 Subjects}
The example differs from the previous one in three ways.  First, Gen1 subjects are used.  Second, standardized height is used instead of math.  Third, pairs are dropped if their \emph{R} is zero; we return to this last issue after the code is run.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{### R Code for Example lavaan estimation analysis with a simple outcome and Gen1 subjects}
\hlcom{#Steps 1-5 are explained in the vignette's first example:}
\hlkwd{require}\hlstd{(NlsyLinks)}
\hlstd{dsLinking} \hlkwb{<-} \hlkwd{subset}\hlstd{(Links79Pair, RelationshipPath}\hlopt{==}\hlstr{"Gen1Housemates"}\hlstd{)}
\hlstd{dsOutcomes} \hlkwb{<-} \hlstd{ExtraOutcomes79}
\hlcom{#The HeightZGenderAge variable is already groomed}

\hlcom{#Step 6: Create the single entered dataset.}
\hlstd{dsSingle} \hlkwb{<-} \hlkwd{CreatePairLinksSingleEntered}\hlstd{(}\hlkwc{outcomeDataset}\hlstd{=dsOutcomes,}
  \hlkwc{linksPairDataset}\hlstd{=dsLinking,} \hlkwc{outcomeNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'HeightZGenderAge'}\hlstd{))}

\hlcom{#Step 7: Declare the names for the two outcome variables. }
\hlstd{oName_S1} \hlkwb{<-} \hlstr{"HeightZGenderAge_S1"}
\hlstd{oName_S2} \hlkwb{<-} \hlstr{"HeightZGenderAge_S2"}

\hlcom{#Step 8: Summarize the R groups and determine which groups can be estimated.}
\hlstd{dsGroupSummary} \hlkwb{<-} \hlkwd{RGroupSummary}\hlstd{(dsSingle, oName_S1, oName_S2)}
\hlstd{rGroupsToDrop} \hlkwb{<-} \hlkwd{c}\hlstd{(} \hlnum{0} \hlstd{)}
\hlstd{dsGroupSummary[dsGroupSummary}\hlopt{$}\hlstd{R} \hlopt{%in%} \hlstd{rGroupsToDrop,} \hlstr{"Included"}\hlstd{]} \hlkwb{<-} \hlnum{FALSE}
\hlstd{dsGroupSummary}
\end{alltt}
\begin{verbatim}
##        R Included PairCount   O1Mean    O2Mean O1Variance O2Variance O1O2Covariance
## 1 0.0625     TRUE        37 -0.39797  0.019119     0.7872     0.9773        0.37990
## 2 0.1250     TRUE        63 -0.15982 -0.455057     0.9499     0.9529        0.09187
## 3 0.2500     TRUE       267  0.05476  0.006209     0.9853     1.1350        0.26929
## 4 0.5000     TRUE      3778 -0.02323 -0.023449     0.9769     1.0194        0.44371
## 5 1.0000     TRUE        11  0.02395  0.146080     0.2909     0.6106        0.37473
##   Correlation Determinant PosDefinite
## 1     0.43312     0.62499        TRUE
## 2     0.09656     0.89677        TRUE
## 3     0.25465     1.04577        TRUE
## 4     0.44465     0.79890        TRUE
## 5     0.88917     0.03719        TRUE
\end{verbatim}
\begin{alltt}
\hlcom{#Step 9: Create a cleaned dataset}
\hlstd{dsClean} \hlkwb{<-} \hlkwd{CleanSemAceDataset}\hlstd{(}\hlkwc{dsDirty}\hlstd{=dsSingle, dsGroupSummary, oName_S1, oName_S2)}

\hlcom{#Step 10: Run the model}
\hlstd{ace} \hlkwb{<-} \hlkwd{AceLavaanGroup}\hlstd{(dsClean)}
\hlstd{ace}
\end{alltt}
\begin{verbatim}
## [1] "Results of ACE estimation: [show]"
##  ASquared  CSquared  ESquared CaseCount 
##    0.8834    0.0087    0.1079 4156.0000
\end{verbatim}
\begin{alltt}
\hlcom{#Step 11: Inspect the output further (see the final step in the previous example).}
\end{alltt}
\end{kframe}
\end{knitrout}


Most of them responded they were \code{Non-relative}s  to the explict items asked in 1979 (\emph{i.e.}, NLSY79 variables \code{R00001.50} through \code{R00001.59}).  Yet their height's observed correlations is far larger than would be expected for a sample of unrelated subjects.  Since our team began BG research with the NLSY in the mid-1990s, the $R$=0 group has consistently presented higher than expected correlations, across many domains of outcome variables.  For a long time, we have substantial doubts that subject pairs in this group share a low proportion of their selective genes.  Consequently, we suggest applied researchers consider excluding this group from their biometric analyses.  **Joe, is there anything else you'd like to say about this here?**

If you wish to exclude additional groups from the analyses, one line of code in Step 8 should change.  For instance, two exclude ambiguous sibs (in addition to $R=0$ pairs), change\\ \code{rGroupsToDrop <- c( 0 )} \\to \\ \code{rGroupsToDrop <- c( 0, .375 )}.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example: Midstream data manipulation with SAS}
The example differs from the previous one substantial way: After \R{} is used to link the related pairs, and connect them to their outcome values, the dataset is exported so that the user can further manipulate the data in SAS.  

After a presentation, several audience members at the 2012 BGA meeting informed us that this vignette example would help them be more efficient.  This approach is also consistent with our feeling that analysts should use the workflow tools that are best suited to their needs and capabilities.

**Should we export/import as CSVs (which would make the R code much simpler, because the \pkg{foreign} package wouldn't have to be loaded), but increase the code necessary on the SAS side? I really don't want to mess with sasbdats and xports.**

\appendix
\section{Appendix: Receiving Help for the NlsyLinks Package}
\label{sec:ReceivingHelp} A portion of our current grant covers a small, part-time support
staff.  If you have questions about BG research with our kinship links, or
questions about our package, we'd like to hear from you.

We provide personal support for researchers in several ways.  Perhaps the best
place to start are the forums on R-Forge
(\url{http://r-forge.r-project.org/forum/?group_id=1330}); there are forums for
people using \R{}, as well as other software such as SAS.  \href{https://r-forge.r-project.org/forum/forum.php?thread_id=4537&forum_id=4266&group_id=1330}{This
post} is a good overview of the current project is, which originally was an
email Joe sent to previous users of our kinship links (many of them are/were SAS
users).

\section{Appendix: Creating and Saving R Scripts}
\label{sec:RScripts} There are several options and environments for executing \R{} code.  Our current
recommendation is \href{http://rstudio.org/}{RStudio}, because it is easy to
install, and has features targeting beginnner and experienced \R{} users. 
We've had good experiences with it on Windows, OS X, and Ubuntu Linux.

RStudio allows you to create and save \R{} files; these are simply text files
that have an file extension of `.R'.  RStudio will execute the commands written
in the file.  Help documentation for RStudio can be found at
\url{http://www.rstudio.com/ide/docs/}.

\section{Appendix: Installing and Loading the NlsyLinks Package} \label{sec:InstallingPackage}
There are three operations you'll typically do with a package: (a) install, (b) load, and (c) update.

The simplest way to \textbf{install} \pkg{NlsyLinks} is to type
\code{install.packages("NlsyLinks")}.  You may be asked to select a CRAN
mirror to download the package from; if so, choose a close location.

\R{} then will download \pkg{NlsyLinks} on your local computer.  It may
try to save and install the package to a location that you don't have permission to
write files in.  If so, \R{} will ask if you would like to install it to a
better location (\emph{i.e.}, somewhere you do have permission to write files). 
Approve this decision (which is acceptable for everyone except for some network
administrators).

For a given computer, you'll need to \emph{install} a package only once for each
version of \R{} (new versions of \R{} are released every few months).  However, you'll need to \emph{load} a package in
every session that you call its functions.  To \textbf{load} \pkg{NlsyLinks},
type either \code{library(NlsyLinks)} or \code{require(NlsyLinks)}; (the
difference between the two commands is likely irrelevant for your uses.) 
Loading reads \pkg{NlsyLinks} information from the hard drive and places it in
temporary memory.  Once it's loaded, you won't need to load it again until \R{}
is closed and reopened later.

Developers are continually improving their packages by adding functions and
documentation.  These newer versions are then uploaded to the CRAN servers.  You
may \textbf{update} all your installed packages at once by typing
\code{update.packages()}.  The command checks a CRAN server for
newer versions of the packages installed on your local machine.  Then they are
automatically downloaded and installed. 

The grant supporting \pkg{NlsyLinks} extends until Summer 2014.  Until then,
we'll be including new features and documentation, as we address additional user
needs (if you have suggestions, we'd like to hear from you).  When the NLSY periodically updates its data, we'll
update our kinship links (embedded in \pkg{NlsyLinks}) with the newest information.
\section{Appendix: References} \label{sec:References}
\href{http://psych.colorado.edu/~carey/hgss/}{Carey, Gregory (2002)}. \emph{Human Genetics for the Social Sciences}. Sage.

\href{http://books.google.com/books?id=r7AgAQAAIAAJ&source=gbs_navlinks_s}{Plomin, Robert (1990)}. \emph{Nature and nurture: an introduction to human behavioral genetics}.  Brooks/Cole Publishing Company.

\href{http://www.springerlink.com/content/n3x1v1q282583366}{Rodgers, Joseph Lee, \& Kohler, Hans-Peter (2005)}. Reformulating and simplifying the DF analysis model. \emph{Behavior Genetics, 35 (2)}, 211-217.

\href{http://psycnet.apa.org/journals/dev/30/3/374/}{Rodgers, Joseph Lee, Rowe, David C., \& Li, Chengchang (1994)}. Beyond nature versus nurture: DF analysis of nonshared influences on problem behaviors. \emph{Developmental Psychology, 30 (3)}, 374-384. 

\href{http://books.google.com/books/about/Methodology_for_genetic_studies_of_twins.html?id=vVzDmDv6WDkC}{Neale, Michael C., \& Cardon, Lou R. (1992)}. \emph{Methodology for genetic studies of twins and families}. Norwell, MA: Kluwer Academic Publishers. (Also see Neale \& Maes: \url{http://www.vipbg.vcu.edu/OpenMxFall09/NMbook05.pdf}).
 
\section{Notes}
This package's development was largely supported by the NIH Grant 1R01HD65865, \href{http://taggs.hhs.gov/AwardDetail.cfm?s_Award_Num=R01HD065865&n_Prog_Office_Code=50}{``NLSY Kinship Links: Reliable and Valid Sibling Identification"} (PI: Joe Rodgers; Vignette Construction by Will Beasley)

\section{Version Information}
\begin{itemize}\raggedright
  \item R version 3.0.2 (2013-09-25), \verb|x86_64-w64-mingw32|
  \item Locale: \verb|LC_COLLATE=English_United States.1252|, \verb|LC_CTYPE=English_United States.1252|, \verb|LC_MONETARY=English_United States.1252|, \verb|LC_NUMERIC=C|, \verb|LC_TIME=English_United States.1252|
  \item Base packages: base, datasets, graphics, grDevices, methods, stats,
    utils
  \item Other packages: boot~1.3-9, knitr~1.5, lavaan~0.5-14, MASS~7.3-29,
    mnormt~1.4-5, NlsyLinks~1.226, pbivnorm~0.5-1, quadprog~1.5-5
  \item Loaded via a namespace (and not attached): evaluate~0.5.1,
    formatR~0.10, highr~0.3, stats4~3.0.2, stringr~0.6.2, tools~3.0.2
\end{itemize}



%\printindex
\end{document}
